{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sc\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "from tensorflow_probability import distributions as tfd\n",
    "from tensorflow_probability import bijectors as tfb\n",
    "from scipy import io\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import mixture\n",
    "import joblib as jbl\n",
    "import sys\n",
    "from fitter import Fitter\n",
    "sys.path.append('C:/Users/tewar/Documents/work/BNAF-master/data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finite different gradient\n",
    "def gradientFiniteDifferent(func,theta,delta=1E-8):\n",
    "    n = np.size(theta)\n",
    "    grad = np.zeros((n))\n",
    "    for i in range(n):\n",
    "        theta_p=np.copy(theta)\n",
    "        theta_m=np.copy(theta)\n",
    "        theta_p[i]=theta_p[i]+delta\n",
    "        theta_m[i]=theta_m[i]-delta\n",
    "        f_plus = func(tf.constant(theta_p,dtype=tf.float64)).numpy()\n",
    "        f_minus = func(tf.constant(theta_m,dtype=tf.float64)).numpy()\n",
    "        grad[i] = (f_plus-f_minus)/(2*delta)\n",
    "    return grad\n",
    "\n",
    "def GMM_best_fit(samples,max_ncomp=10, print_info=False):\n",
    "    lowest_bic = np.infty\n",
    "    bic = []\n",
    "    for n_components in np.arange(8,max_ncomp):\n",
    "        # Fit a Gaussian mixture with EM\n",
    "        gmm = mixture.GaussianMixture(n_components=n_components+1,covariance_type='full',max_iter=200,n_init=5)\n",
    "        gmm.fit(samples)\n",
    "        if print_info:\n",
    "            print('Fittng a GMM on samples with %s components: BIC=%f'%(n_components,gmm.bic(samples)))\n",
    "        bic.append(gmm.bic(samples))\n",
    "        if bic[-1] < lowest_bic:\n",
    "            lowest_bic = bic[-1]\n",
    "            best_gmm = gmm    \n",
    "    return best_gmm\n",
    "\n",
    "# Numerically finding the icdf values for a distribution whos analytical CDF is specified\n",
    "def icdf_numerical(u,cdf_funct,lb,ub):\n",
    "    # setting up the numerical method (Chandrupatla root finding algorithm) to find icdf\n",
    "    obj_func = lambda x: cdf_funct(x) - u\n",
    "    # finding the roots\n",
    "    x = tfp.math.find_root_chandrupatla(obj_func,low=lb,high=ub)[0]\n",
    "    return x\n",
    "\n",
    "# Standardize GMM parameters\n",
    "def standardize_gmm_params(alphas,mus,covs):\n",
    "    weighted_mus = tf.linalg.matvec(tf.transpose(mus),alphas)\n",
    "    new_mus = mus - weighted_mus\n",
    "    variances = tf.linalg.diag_part(covs)\n",
    "    scaling_vec = tf.linalg.matvec(tf.transpose(new_mus**2+variances),alphas)\n",
    "    scaling_matrix = tf.linalg.diag(1/(scaling_vec**0.5))\n",
    "    new_mus = tf.linalg.matmul(new_mus,scaling_matrix)\n",
    "    new_covs = tf.linalg.matmul(covs,scaling_matrix**2)\n",
    "    return alphas,new_mus,new_covs\n",
    "\n",
    "# Function to compute numerical gradient using central finite difference\n",
    "def gradientFiniteDifferent(func,theta,delta=1E-4):\n",
    "    n = np.size(theta)\n",
    "    grad = np.zeros((n))\n",
    "    for i in range(n):\n",
    "        theta_p=np.copy(theta)\n",
    "        theta_m=np.copy(theta)\n",
    "        theta_p[i]=theta_p[i]+delta\n",
    "        theta_m[i]=theta_m[i]-delta\n",
    "        f_plus = func(tf.constant(theta_p,dtype=tf.float32)).numpy()\n",
    "        f_minus = func(tf.constant(theta_m,dtype=tf.float32)).numpy()\n",
    "        grad[i] = (f_plus-f_minus)/(2*delta)\n",
    "    return grad\n",
    "\n",
    "def vec2gmm_params(n_dims,n_comps,param_vec):\n",
    "    num_alpha_params = n_comps\n",
    "    num_mu_params = n_comps*n_dims\n",
    "    num_sig_params = int(n_comps*n_dims*(n_dims+1)*0.5)\n",
    "    logit_param, mu_param, chol_param = tf.split(param_vec,[num_alpha_params,num_mu_params,num_sig_params])\n",
    "    mu_vectors = tf.reshape(mu_param, shape=(n_comps,n_dims))\n",
    "    chol_mat_array=tf.TensorArray(tf.float32,size=n_comps)\n",
    "    cov_mat_array=tf.TensorArray(tf.float32,size=n_comps)\n",
    "    for k in range(n_comps):\n",
    "        start_idx = tf.cast(k*(num_sig_params/n_comps),tf.int32)\n",
    "        end_idx = tf.cast((k+1)*(num_sig_params/n_comps),tf.int32)\n",
    "        chol_mat = tfb.FillScaleTriL(diag_bijector=tfb.Exp()).forward(chol_param[start_idx:end_idx])\n",
    "        cov_mat = tf.matmul(chol_mat,tf.transpose(chol_mat))\n",
    "        chol_mat_array = chol_mat_array.write(k,chol_mat) \n",
    "        cov_mat_array =  cov_mat_array.write(k,cov_mat) \n",
    "        \n",
    "    chol_matrices = chol_mat_array.stack()\n",
    "    cov_matrices = cov_mat_array.stack()     \n",
    "    return [logit_param,mu_vectors,cov_matrices,chol_matrices]\n",
    "\n",
    "def gmm_params2vec(n_dims,n_comps,alphas,mu_vectors,cov_matrices):\n",
    "    # now gathering all the parameters into a single vector\n",
    "    param_list = []\n",
    "    param_list.append(np.log(alphas))\n",
    "    param_list.append(tf.reshape(mu_vectors,-1))\n",
    "    for k in range(n_comps):\n",
    "        chol_mat = tf.linalg.cholesky(cov_matrices[k])\n",
    "        param_list.append(tfb.FillScaleTriL(diag_bijector=tfb.Exp()).inverse(chol_mat))\n",
    "    param_vec = tf.concat(param_list,axis=0)\n",
    "    return param_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GMC bijector\n",
    "class GMC_bijector(tfb.Bijector):\n",
    "    def __init__(self,n_dims,n_comps,param_list,forward_min_event_ndims=1, validate_args: bool = False,name=\"gmc\"):\n",
    "        super(GMC_bijector, self).__init__(\n",
    "            validate_args=validate_args, forward_min_event_ndims=forward_min_event_ndims, name=name\n",
    "        )\n",
    "        \n",
    "        assert (len(param_list)==3), 'incorrect number of inputs'\n",
    "        assert param_list[1].shape == [n_comps,n_dims], 'the dimension of mean vectors should be ncomps x ndims'\n",
    "        assert param_list[2].shape == [n_comps,n_dims], 'the dimension of variance vectors should be ncomps x ndims'\n",
    "        \n",
    "        self.ndims = n_dims\n",
    "        self.ncomps = n_comps\n",
    "        self.logits = param_list[0]\n",
    "        self.mu_vectors = param_list[1]\n",
    "        self.var_vectors = param_list[2]\n",
    "        self.std_vectors = self.var_vectors**0.5\n",
    "    \n",
    "    def _forward(self, x_mat):\n",
    "        assert x_mat.shape[1] == self.ndims, 'expected data dimensions n_samps x n_dims'\n",
    "        dist = tfd.MixtureSameFamily(mixture_distribution=tfd.Categorical(logits=self.logits),\n",
    "                               components_distribution=tfd.Normal(loc=tf.transpose(self.mu_vectors),\n",
    "                                                                  scale=tf.transpose(self.std_vectors)))\n",
    "        u_mat = dist.cdf(x_mat)\n",
    "        return u_mat\n",
    "    \n",
    "    def _inverse(self, u_mat):\n",
    "        assert u_mat.shape[1] == self.ndims, 'expected data dimensions n_samps x n_dims'\n",
    "        x_mat = self.gmm_icdf_parallel(u_mat,self.logits,tf.transpose(self.mu_vectors),tf.transpose(self.std_vectors))\n",
    "        return x_mat\n",
    "    \n",
    "    def _inverse_log_det_jacobian(self, u_mat):\n",
    "        x_mat = self._inverse(u_mat)\n",
    "        dist = tfd.MixtureSameFamily(mixture_distribution=tfd.Categorical(logits=self.logits),\n",
    "                               components_distribution=tfd.Normal(loc=tf.transpose(self.mu_vectors),\n",
    "                                                                  scale=tf.transpose(self.std_vectors)))\n",
    "        log_det_J_mat = dist.log_prob(x_mat)\n",
    "        return -tf.reduce_sum(log_det_J_mat,axis=1)    \n",
    "    \n",
    "    # Numerically finding the icdf values of univariate gmm distributions (one along each dimension)\n",
    "    @tf.custom_gradient\n",
    "    def gmm_icdf_parallel(self,u_mat,logit,mu_T,std_T):\n",
    "        # Setting up the numerical method to find icdf\n",
    "        # first define a function that computes the residual between the actual true CDF values and the CDF value as specified matrix\n",
    "        obj_func = lambda x: tfd.MixtureSameFamily(mixture_distribution=tfd.Categorical(logits=logit),\n",
    "                                                   components_distribution=tfd.Normal(loc=mu_T,scale=std_T)).cdf(x)-u_mat\n",
    "        # specifying the lower and upper bounds of the root based on current parameters\n",
    "        lb = tf.reduce_min(mu_T,axis=1) - 5*tf.reduce_max(std_T,axis=1)\n",
    "        ub = tf.reduce_max(mu_T,axis=1) + 5*tf.reduce_max(std_T,axis=1)\n",
    "        # replicating the lower and upper bounds\n",
    "        lb = tf.repeat(tf.reshape(lb,[1,-1]),u_mat.shape[0],axis=0)\n",
    "        ub = tf.repeat(tf.reshape(ub,[1,-1]),u_mat.shape[0],axis=0)\n",
    "        # finding the roots (Chandrupatla root finding algorithm)\n",
    "        x_mat = tfp.math.find_root_chandrupatla(obj_func,low=lb,high=ub)[0]\n",
    "        # following code implements custom gradient\n",
    "        def grad(dy):\n",
    "            # Calling  another python function to get the partial derivatives\n",
    "            grad_logit, grad_mu, grad_std = self.partial_deriv_z(x_mat,logit,mu_T,std_T)\n",
    "\n",
    "            temp_mat = tf.linalg.matmul(grad_logit,dy)\n",
    "\n",
    "            logit_grad = tf.linalg.diag_part(temp_mat)\n",
    "            logit_grad = tf.reduce_sum(logit_grad,axis=1)\n",
    "\n",
    "            temp_mat = tf.linalg.matmul(grad_mu,dy)\n",
    "            mu_grad = tf.linalg.diag_part(temp_mat)\n",
    "\n",
    "            temp_mat = tf.linalg.matmul(grad_std,dy)\n",
    "            std_grad = tf.linalg.diag_part(temp_mat)\n",
    "            \n",
    "            return tf.constant(0.,shape=(u_mat.shape)), logit_grad, tf.transpose(mu_grad), tf.transpose(std_grad)    \n",
    "        return x_mat, grad\n",
    "    \n",
    "    # Analytical partial derivative of icdf of Gaussian Mixture marginals\n",
    "    def partial_deriv_z(self,z,logit,mu_T,std_T):\n",
    "        alpha = tf.math.softmax(logit)\n",
    "        grad_logit_array = tf.TensorArray(tf.float32, size=self.ncomps)\n",
    "        grad_mu_array = tf.TensorArray(tf.float32, size=self.ncomps)\n",
    "        grad_var_array = tf.TensorArray(tf.float32, size=self.ncomps)        \n",
    "        dist = tfd.MixtureSameFamily(mixture_distribution=tfd.Categorical(logits=logit),\n",
    "                                components_distribution=tfd.Normal(loc=mu_T,\n",
    "                                                                   scale=std_T))\n",
    "        common_factor1 = dist.prob(z)\n",
    "        for k in range(self.ncomps):        \n",
    "            common_factor2 = tfd.Normal(loc=mu_T[:,k],scale=std_T[:,k]).prob(z)\n",
    "            term = 0.5*(1+tf.math.erf((z-mu_T[:,k])/(tf.math.sqrt(2.)*std_T[:,k])))\n",
    "            v1 = -alpha[k]*(term - dist.cdf(z))/common_factor1\n",
    "            v2 = alpha[k]*common_factor2/common_factor1\n",
    "            v3 = v2 * ((z-mu_T[:,k])/(std_T[:,k])) \n",
    "\n",
    "            grad_logit_array = grad_logit_array.write(k, tf.transpose(v1) )\n",
    "            grad_mu_array = grad_mu_array.write(k, tf.transpose(v2) )\n",
    "            grad_var_array = grad_var_array.write(k, tf.transpose(v3) )\n",
    "        return grad_logit_array.stack(), grad_mu_array.stack(), grad_var_array.stack()\n",
    "    \n",
    " # Marignal transform bijector\n",
    "class Marginal_transform(tfb.Bijector):\n",
    "    def __init__(self,ndims,marg_dist_list,forward_min_event_ndims=1, validate_args: bool = False,name=\"marginals\"):\n",
    "        super(Marginal_transform, self).__init__(\n",
    "            validate_args=validate_args, forward_min_event_ndims=forward_min_event_ndims, name=name\n",
    "        )\n",
    "        self.ndims = ndims\n",
    "        self.marg_dists = marg_dist_list\n",
    "    \n",
    "    def _inverse(self, x_mat):\n",
    "        nobs = x_mat.get_shape().as_list()[0]\n",
    "        temp_array = tf.TensorArray(tf.float32,size=self.ndims)\n",
    "        for j in range(self.ndims):\n",
    "            u_cur = self.marg_dists[j]['cdf'](x_mat[:,j])\n",
    "            temp_array = temp_array.write(j,u_cur)\n",
    "        u_mat = tf.transpose(temp_array.stack())            \n",
    "        return u_mat\n",
    "    \n",
    "    def _forward(self, u_mat):\n",
    "        temp_array = tf.TensorArray(tf.float32,size=self.ndims)\n",
    "        for j in range(self.ndims):\n",
    "            x_cur = icdf_numerical(u_mat[:,j], self.marg_dists[j]['cdf'],self.marg_dists[j]['lb'],self.marg_dists[j]['ub'])\n",
    "            temp_array = temp_array.write(j,x_cur)\n",
    "        x_mat = tf.transpose(temp_array.stack())              \n",
    "        return x_mat\n",
    "    \n",
    "    def _forward_log_det_jacobian(self, u_mat):\n",
    "        x_mat = self._forward(u_mat)\n",
    "        temp_array = tf.TensorArray(tf.float32,size=self.ndims)\n",
    "        for j in range(self.ndims):\n",
    "            temp_array = temp_array.write(j,self.marg_dists[j]['log_pdf'](x_mat[:,j]))\n",
    "        log_det_J_mat = tf.transpose(temp_array.stack())\n",
    "        return -tf.reduce_sum(log_det_J_mat,axis=1) \n",
    "    \n",
    "    def _inverse_log_det_jacobian(self, x_mat):\n",
    "        u_mat = self._inverse(x_mat)\n",
    "        return -self._forward_log_det_jacobian(u_mat)   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Defining GMC class\n",
    "class GMC:\n",
    "    def __init__(self, n_dims, n_comps, param_vec):        \n",
    "        self.ndims = n_dims\n",
    "        self.ncomps = n_comps   \n",
    "        self.total_trainable_params = int(n_comps*(1+n_dims+0.5*n_dims*(n_dims+1)))\n",
    "        self.params = param_vec\n",
    "        assert tf.size(param_vec) == self.total_trainable_params, 'the supplied parameter vector is not commensurate with the n_dims, and n_comps'\n",
    "        \n",
    "    @property\n",
    "    def distribution(self):\n",
    "        # transforming vector in to parameters\n",
    "        logits,mus,covs,chols = vec2gmm_params(self.ndims,self.ncomps,self.params)\n",
    "        # Instantiating the bijector\n",
    "        gmc_bijector = GMC_bijector(self.ndims, self.ncomps, [logits, mus, tf.linalg.diag_part(covs)])\n",
    "        # Specifying the base distribution\n",
    "        base_dist = tfd.MixtureSameFamily(tfd.Categorical(logits=logits),\n",
    "                                          tfd.MultivariateNormalTriL(loc=mus,scale_tril=chols))\n",
    "        # Instnatiating the gmc distribution as a transformed distribtution\n",
    "        gmc_dist = tfd.TransformedDistribution(distribution=base_dist,bijector=gmc_bijector)    \n",
    "        return gmc_dist   \n",
    "    \n",
    "    @property\n",
    "    def identifiability_prior(self):\n",
    "        # transforming vector in to parameters\n",
    "        logits,mus,covs,_ = vec2gmm_params(self.ndims,self.ncomps,self.params)        \n",
    "        alphas = tf.math.softmax(logits)\n",
    "        variances = tf.linalg.diag_part(covs)        \n",
    "        vec1 = tf.linalg.matvec(tf.transpose(mus),alphas)\n",
    "        vec2 = tf.linalg.matvec(tf.transpose(variances + mus**2),alphas)\n",
    "        log_prior_1 = tfd.MultivariateNormalDiag(loc=tf.zeros(self.ndims),scale_diag=1E-1*tf.ones(self.ndims)).log_prob(vec1)\n",
    "        log_prior_2 = tfd.MultivariateNormalDiag(loc=tf.ones(self.ndims) ,scale_diag=1E-1*tf.ones(self.ndims)).log_prob(vec2)\n",
    "        return log_prior_1,log_prior_2\n",
    "    \n",
    "\n",
    "    \n",
    "class GMCM:\n",
    "    def __init__(self, n_dims, data_in, forward_transform=None, marginals_list=None, gmc=None):\n",
    "        \n",
    "        self.ndims = n_dims\n",
    "        self.data_transform = forward_transform\n",
    "        self.gmc = gmc\n",
    "        if gmc is not None:\n",
    "            self.ncomps = gmc.ncomps\n",
    "        \n",
    "        if forward_transform is not None:\n",
    "            data_in = forward_transform.inverse(data_in).numpy()\n",
    "        self.data_in = data_in\n",
    "        \n",
    "        if marginals_list is None:\n",
    "            print('Learning Marginals')\n",
    "            ts = time.time()\n",
    "            marginals_list = self.learn_marginals()\n",
    "            print(f'Marginals learnt in {np.round(time.time()-ts,2)} s.') \n",
    "        \n",
    "        self.marg_dists = marginals_list\n",
    "        self.marg_bijector = Marginal_transform(self.ndims,self.marg_dists)       \n",
    "        \n",
    "    @property\n",
    "    def distribution(self):\n",
    "        # setting the gmcm distribution as a transformed distribution of gmc_distribution\n",
    "        gmcm_dist = tfd.TransformedDistribution(distribution=self.gmc.distribution,bijector=self.marg_bijector)\n",
    "        if self.data_transform is not None:\n",
    "            gmcm_dist = tfd.TransformedDistribution(distribution=gmcm_dist,bijector=self.data_transform)\n",
    "        return gmcm_dist\n",
    "    \n",
    "    \n",
    "    def learn_marginals(self):\n",
    "        # fitting marginal distributions first\n",
    "        marg_dist_list=[]\n",
    "        for j in range(self.ndims):\n",
    "            input_vector = self.data_in[:,j].reshape(-1,1)\n",
    "            marg_gmm_obj = GMM_best_fit(input_vector,max_ncomp=10)\n",
    "            marg_gmm_tfp = tfd.MixtureSameFamily(mixture_distribution=tfd.Categorical(probs=marg_gmm_obj.weights_.flatten().astype('float32')),\n",
    "                                                components_distribution=tfd.Normal(loc=marg_gmm_obj.means_.flatten().astype('float32'),\n",
    "                                                                                   scale = marg_gmm_obj.covariances_.flatten().astype('float32')**0.5),)\n",
    "            \n",
    "            # creating a dictionary containing necessary information about each marginal distribution\n",
    "            info_dict={'cdf':marg_gmm_tfp.cdf,\n",
    "                       'log_pdf':marg_gmm_tfp.log_prob,\n",
    "                       'lb':tf.reduce_min(input_vector)-3*tfp.stats.stddev(input_vector),\n",
    "                       'ub':tf.reduce_max(input_vector)+3*tfp.stats.stddev(input_vector)                         \n",
    "                      }\n",
    "            \n",
    "            marg_dist_list.append(info_dict)\n",
    "        \n",
    "        return marg_dist_list\n",
    "        \n",
    "    def init_GMC_params(self,initialization=['random',None]):\n",
    "        # Initializing the GMC params \n",
    "        init_method, seed_val = initialization\n",
    "        if init_method == 'random':\n",
    "            if seed_val is not None:\n",
    "                np.random.seed(seed_val)\n",
    "            alphas = tf.ones(self.ncomps)/self.ncomps\n",
    "            mus = tf.constant(np.random.randn(self.ncomps,self.ndims).astype('float32'))\n",
    "            covs = tf.repeat(tf.expand_dims(tf.eye(self.ndims),0),self.ncomps,axis=0)\n",
    "        elif init_method == 'gmm':            \n",
    "            gmm = mixture.GaussianMixture(n_components=self.ncomps,covariance_type='full',max_iter=1000,n_init=5)\n",
    "            gmm.fit(self.data_in)\n",
    "            alphas = gmm.weights_.astype('float32')\n",
    "            mus = gmm.means_.astype('float32')\n",
    "            covs = gmm.covariances_.astype('float32')                                                            \n",
    "        \n",
    "        # changing the parameters to standardize the resulting gmm\n",
    "        alphas,mus,covs = standardize_gmm_params(alphas,mus,covs)\n",
    "        # now initializing trainable parameters\n",
    "        init_params = tf.Variable(gmm_params2vec(self.ndims,self.ncomps,alphas,mus,covs))\n",
    "        \n",
    "        return init_params\n",
    "    \n",
    "    \n",
    "    def fit_GMC_dist(self, n_comps, optimizer = tf.optimizers.Adam(learning_rate=1E-2), initialization = ['random',None], max_iters = 1000, batch_size = 10, print_interval=100, regularize=True, plot_results = False):\n",
    "        self.ncomps = n_comps\n",
    "        # getting the marginal CDF values\n",
    "        u_mat = self.marg_bijector.inverse(self.data_in)\n",
    "        # initializing the parameters\n",
    "        gmc_params = self.init_GMC_params(initialization=initialization)\n",
    "        # instantiation GMC object\n",
    "        gmc_obj = GMC(self.ndims,self.ncomps,gmc_params)\n",
    "        \n",
    "        # Defining the training step\n",
    "        @tf.function\n",
    "        def train_step(u_selected):\n",
    "            with tf.GradientTape() as tape:\n",
    "                neg_gmc_ll = -tf.reduce_mean(gmc_obj.distribution.log_prob(u_selected))\n",
    "                ident_prior = gmc_obj.identifiability_prior\n",
    "                if regularize:\n",
    "                    total_cost = neg_gmc_ll - tf.reduce_sum(ident_prior)\n",
    "                else:\n",
    "                    total_cost = neg_gmc_ll\n",
    "                    \n",
    "            grads = tape.gradient(total_cost, gmc_obj.params)\n",
    "            if not (tf.reduce_any(tf.math.is_nan(grads)) or tf.reduce_any(tf.math.is_inf(grads))):\n",
    "                optimizer.apply_gradients(zip([grads], [gmc_obj.params])) #updating the gmc parameters\n",
    "            return neg_gmc_ll,ident_prior[0],ident_prior[1]\n",
    "\n",
    "        neg_ll_trn = np.empty(max_iters)  \n",
    "        neg_ll_trn[:] = np.NaN\n",
    "        neg_prior_1 = np.empty(max_iters)  \n",
    "        neg_prior_1[:] = np.NaN\n",
    "        neg_prior_2 = np.empty(max_iters)  \n",
    "        neg_prior_2[:] = np.NaN\n",
    "        np.random.seed(10)\n",
    "        ts = time.time() # start time\n",
    "        # Optimization iterations\n",
    "        for itr in np.arange(max_iters):\n",
    "            np.random.seed(itr)\n",
    "            # Executing a training step\n",
    "            samps_idx = np.random.choice(u_mat.shape[0],batch_size)\n",
    "            u_selected_trn = tf.gather(u_mat,samps_idx)\n",
    "            out = train_step(u_selected_trn)\n",
    "            neg_ll_trn[itr] = out[0].numpy()\n",
    "            neg_prior_1[itr] = out[1].numpy()\n",
    "            neg_prior_2[itr] = out[2].numpy()    \n",
    "            # Printing results every 100 iteration    \n",
    "            if tf.equal(itr%print_interval,0) or tf.equal(itr,0):\n",
    "                time_elapsed = np.round(time.time()-ts,1)\n",
    "                print(f'@ Iter:{itr}, Training error: {neg_ll_trn[itr]}, LogPriors: {np.round(neg_prior_1[itr],2), np.round(neg_prior_2[itr],2)}, Time Elapsed: {time_elapsed} s')    \n",
    "        \n",
    "        if plot_results:\n",
    "            # Plotting results\n",
    "            plt.plot(neg_ll_trn)\n",
    "            plt.xlabel('Iteration',fontsize=12)\n",
    "            plt.ylabel('Neg_logLike',fontsize=12)\n",
    "            plt.legend(['train'],fontsize=12)\n",
    "        \n",
    "        # setting gmc distritbution embedded inside GMCM\n",
    "        self.gmc = gmc_obj\n",
    "         \n",
    "        return neg_ll_trn\n",
    "    \n",
    "    def get_marginal(self,dim_list):        \n",
    "        data_in_new = tf.gather(self.data_in,dim_list,axis=1).numpy()\n",
    "        logits,mus,covs,_ = vec2gmm_params(self.ndims,self.ncomps,self.gmc.params)\n",
    "        alphas = tf.math.softmax(logits)\n",
    "        dim_remove = list(set(list(range(self.ndims)))-set(dim_list))\n",
    "        mus_new = tf.gather(mus, dim_list, axis=1)\n",
    "        covs_new = tf.TensorArray(tf.float32,self.ncomps)\n",
    "        for k in range(self.ncomps):\n",
    "            temp_mat = covs[k].numpy()\n",
    "            covs_new = covs_new.write(k,temp_mat[np.ix_(dim_list,dim_list)])\n",
    "        covs_new = covs_new.stack()\n",
    "        # getting the gmc object first for the marginal gmcm\n",
    "        marginal_gmc_params = gmm_params2vec(len(dim_list),self.ncomps,alphas,mus_new,covs_new)\n",
    "        marg_gmc = GMC(len(dim_list),self.ncomps,marginal_gmc_params)\n",
    "        # then getting the marginals along the specified dimensions\n",
    "        marg_list_new = []\n",
    "        for j in range(self.ndims):\n",
    "            if j in dim_list:\n",
    "                marg_list_new.append(self.marg_dists[j])\n",
    "        # creating the marginal gmcm object\n",
    "        marg_gmcm_dist = GMCM(len(dim_list), data_in_new, forward_transform=self.data_transform, marginals_list=marg_list_new, gmc=marg_gmc)\n",
    "        return marg_gmcm_dist   \n",
    "    \n",
    "    def get_conditional(self,obs_dim_list, value_list):\n",
    "        \n",
    "        x_obs = np.array(value_list).reshape(1,-1).astype('float32')\n",
    "        unobs_dim_list = list(set(range(self.ndims)) - set(obs_dim_list))\n",
    "        \n",
    "        #Obtaining the marginal distribution for the observed and missing part\n",
    "        gmcm_observed = self.get_marginal(obs_dim_list)\n",
    "        gmcm_unobserved = self.get_marginal(unobs_dim_list)\n",
    "        \n",
    "        temp_obj = gmcm_observed\n",
    "        z_obs = np.copy(x_obs)\n",
    "        while hasattr(temp_obj.distribution,'bijector'):\n",
    "            z_obs = temp_obj.distribution.bijector.inverse(z_obs).numpy()\n",
    "            temp_obj = temp_obj.distribution\n",
    "\n",
    "        #Obtaining the conditional mu and Sigma of individual compoents of the missing part given the data of observed part\n",
    "        mus_cond = np.zeros((self.ncomps,len(unobs_dim_list))).astype('float32')\n",
    "        covs_cond = np.zeros((self.ncomps,len(unobs_dim_list), len(unobs_dim_list))).astype('float32')\n",
    "        logits_cond = np.zeros(self.ncomps).astype('float32')\n",
    "        \n",
    "        logits,mus,covs,_ = vec2gmm_params(self.ndims,self.ncomps,self.gmc.params)\n",
    "        logits_unobs,mus_unobs,covs_unobs,_ = vec2gmm_params(gmcm_unobserved.ndims,gmcm_unobserved.ncomps,gmcm_unobserved.gmc.params)\n",
    "        logits_obs,mus_obs,covs_obs,_ = vec2gmm_params(gmcm_observed.ndims,gmcm_observed.ncomps,gmcm_observed.gmc.params)\n",
    "        \n",
    "        for k in range(self.ncomps):\n",
    "            sig_11 = covs_unobs.numpy()[k]\n",
    "            sig_22 = covs_obs.numpy()[k]\n",
    "            sig_12 = covs.numpy()[k][np.ix_(unobs_dim_list,obs_dim_list)]\n",
    "            sig_21 = sig_12.T\n",
    "            mu_11 = mus_unobs[k,:]\n",
    "            mu_22 = mus_obs[k,:]\n",
    "            \n",
    "#             temp_mat1 = np.concatenate([np.concatenate([sig_11,sig_12],axis=1),np.concatenate([sig_21,sig_22],axis=1)],axis=0)\n",
    "#             temp_mat2=covs.numpy()[k]\n",
    "#             lll = unobs_dim_list+obs_dim_list\n",
    "#             temp_mat2 = temp_mat2[:,lll]\n",
    "#             temp_mat2 = temp_mat2[lll,:]\n",
    "#             print(temp_mat1-temp_mat2)\n",
    "            \n",
    "\n",
    "            # Getting the conditional mu and Sigma\n",
    "            mu_bar = mu_11 + np.matmul(sig_12,  np.linalg.solve(sig_22,z_obs.T)).flatten()\n",
    "            sig_bar = sig_11 - np.matmul(sig_12,  np.linalg.solve(sig_22,sig_21))\n",
    "            mus_cond[k] = mu_bar\n",
    "            covs_cond[k] = (sig_bar+sig_bar.T)/2\n",
    "\n",
    "            # Getting the log proability of the components conditioned on the observed data\n",
    "            logits_cond[k] = logits_obs[k] + tfd.MultivariateNormalFullCovariance(loc=mus_obs[k],\n",
    "                                                                                         covariance_matrix=covs_obs[k]).log_prob(z_obs)\n",
    "        #logits to probabilities\n",
    "        alphas_cond = tf.math.softmax(logits_cond)\n",
    "        # parameter vector of the conditional gmc distribution\n",
    "        conditional_gmc_params = gmm_params2vec(len(unobs_dim_list),self.ncomps,alphas_cond,mus_cond,covs_cond)\n",
    "        cond_gmc = GMC(len(unobs_dim_list),self.ncomps,conditional_gmc_params)\n",
    "        # then getting the marginals along the specified dimensions\n",
    "        marg_list_new = []\n",
    "        for j in range(self.ndims):\n",
    "            if j in unobs_dim_list:\n",
    "                marg_list_new.append(self.marg_dists[j])\n",
    "        # creating the conditional gmcm object\n",
    "        data_in_new = tf.gather(self.data_in,unobs_dim_list,axis=1).numpy()\n",
    "        cond_gmcm_dist = GMCM(len(unobs_dim_list), data_in_new, forward_transform=self.data_transform, marginals_list=marg_list_new, gmc=cond_gmc)\n",
    "        return cond_gmcm_dist  \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set = ['GAS','POWER','HEPMASS']\n",
    "\n",
    "from gas import GAS\n",
    "from power import POWER\n",
    "from hepmass import HEPMASS\n",
    "\n",
    "n_reps = 100\n",
    "ll_list = []\n",
    "\n",
    "for i in range(3):\n",
    "    if data_set[i] is 'GAS':\n",
    "        gg=GAS('C:/Users/tewar/Documents/work/GMCM/data/gas/ethylene_CO.pickle')\n",
    "    elif data[i] is 'POWER':\n",
    "        gg=POWER('C:/Users/tewar/Documents/work/GMCM/data/power/data.npy')\n",
    "    elif data_set[i] is 'HEPMASS':\n",
    "        gg=HEPMASS('C:/Users/tewar/Documents/work/GMCM/data/hepmass/')\n",
    "\n",
    "    data = gg.trn.x\n",
    "    nsamps,ndims = data.shape\n",
    "    np.random.seed(0)\n",
    "    idx_selected = np.unique(np.random.randint(0,nsamps,int(nsamps/50)))\n",
    "    data_in = data[idx_selected,:].astype('float32')\n",
    "\n",
    "    nsamps,ndims = data_in.shape\n",
    "    print(f'Number of samples = {nsamps}, Number of dimensions = {ndims}')\n",
    "\n",
    "    min_val = np.min(data_in).astype('float32')-1\n",
    "    shift_exp_bijec = tfb.Chain([tfb.Shift(shift=min_val.astype('float32')),tfb.Exp()])\n",
    "    np.random.shuffle(data_in)\n",
    "    data_in_trn,data_in_tst = np.split(data_in,[int(np.round(nsamps*0.75))])\n",
    "    \n",
    "    gmcm_obj = GMCM(ndims, data_in_trn, forward_transform=shift_exp_bijec)\n",
    "    ll_reg = np.zeros((5000,n_reps))\n",
    "    ll_nonreg = np.zeros((5000,n_reps))\n",
    "    for rep in range(n_reps):\n",
    "        print(rep)\n",
    "        ll_reg[:,rep]=gmcm_obj.fit_GMC_dist(10,max_iters=5000,batch_size=50,initialization=['random',rep], print_interval=500, regularize=True)\n",
    "        ll_nonreg[:,rep]=gmcm_obj.fit_GMC_dist(10,max_iters=5000,batch_size=50,initialization=['random',rep], print_interval=500, regularize=False)\n",
    "        \n",
    "    ll_list.append([ll_reg,ll_nonreg])\n",
    "\n",
    "jbl.dump(ll_list,'regularization_impact')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from power import POWER\n",
    "gg=POWER('C:/Users/tewar/Documents/work/GMCM/data/power/data.npy')\n",
    "data = gg.trn.x\n",
    "nsamps,ndims = data.shape\n",
    "idx_selected = np.unique(np.random.randint(0,nsamps,int(nsamps/50)))\n",
    "data_in = data[idx_selected,:].astype('float32')\n",
    "# data_in = np.random.randn(1000,10).astype('float32')\n",
    "min_val = np.min(data_in).astype('float32')-1\n",
    "shift_exp_bijec = tfb.Chain([tfb.Shift(shift=min_val.astype('float32')),tfb.Exp()])\n",
    "gmcm_obj = GMCM(ndims, data_in, forward_transform=shift_exp_bijec)\n",
    "ll_trn=gmcm_obj.fit_GMC_dist(5,max_iters=5,batch_size=50,initialization=['random',1], print_interval=500, regularize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl,vals = [0, 2, 3, 5], [0.1, -2, 1.2, 3.4]\n",
    "marg_gmcm = gmcm_obj.get_marginal(dl)\n",
    "cond_gmcm = gmcm_obj.get_conditional(dl,vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vv_all = np.array([0.1, 0, -2, 1.2, 0, 3.4]).astype('float32').reshape(1,-1)\n",
    "vv_obs = np.array(vals).astype('float32').reshape(1,-1)\n",
    "vv_unobs = np.array([0.,0.]).astype('float32').reshape(1,-1)\n",
    "print(gmcm_obj.distribution.log_prob(vv_all) - marg_gmcm.distribution.log_prob(vv_obs))\n",
    "print(cond_gmcm.distribution.log_prob(vv_unobs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out1 = vec2gmm_params(gmcm_obj.ndims,gmcm_obj.ncomps,gmcm_obj.gmc.params)\n",
    "out2 = vec2gmm_params(marg_gmcm.ndims, marg_gmcm.ncomps,marg_gmcm.gmc.params)\n",
    "out3 = vec2gmm_params(cond_gmcm.ndims, cond_gmcm.ncomps,cond_gmcm.gmc.params)\n",
    "\n",
    "\n",
    "print(tf.math.softmax(out1[0]))\n",
    "print(tf.math.softmax(out2[0]))\n",
    "print(tf.math.softmax(out3[0]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = gmcm_obj.distribution.sample(10000)\n",
    "data2 = marg_gmcm.distribution.sample(10000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vv =np.array([1,1.,1]).astype('float32').reshape(1,-1)\n",
    "vv1 = marg_gmcm.distribution.bijector.inverse(vv)\n",
    "print(vv1)\n",
    "vv2 = marg_gmcm.distribution.distribution.bijector.inverse(vv1)\n",
    "print(vv2)\n",
    "vv3 = marg_gmcm.distribution.distribution.distribution.bijector.inverse(vv2)\n",
    "print(vv3)\n",
    "\n",
    "obj = marg_gmcm\n",
    "while hasattr(obj.distribution,'bijector'):\n",
    "    vv = obj.distribution.bijector.inverse(vv).numpy()\n",
    "    print(vv)\n",
    "    obj = obj.distribution\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(data1[:,3],data1[:,0],'k.');\n",
    "plt.plot(data2[:,1],data2[:,0],'r.');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.semilogy(ll_trn+10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(ll_1)\n",
    "np.mean(ll_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gmcm_obj.gmc.total_trainable_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_in_tst.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = gmcm_obj.distribution.sample(2000).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id1,id2 = np.random.choice(ndims,2)\n",
    "plt.subplot(121)\n",
    "plt.plot(ss[:,id1],ss[:,id2],'k.')\n",
    "plt.subplot(122)\n",
    "plt.plot(data_in[:,id1],data_in[:,id2],'k.')\n",
    "print([id1,id2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.hist(ss[:,id2],20);\n",
    "plt.hist(data_in[:,id2],50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(np.log(data_in[:,1]+1),50);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('../logs/GAS/LRminus3_NComps60/chkpt/')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def run_chain(init_state,step_size,target_log_prob_fn, unconstraining_bijectors=tfb.Identity(),num_steps=1000,burnin=50):\n",
    "    def trace_fn(_,pkr):\n",
    "        return (\n",
    "            pkr.inner_results.inner_results.target_log_prob,\n",
    "            pkr.inner_results.inner_results.leapfrogs_taken,\n",
    "            pkr.inner_results.inner_results.has_divergence,\n",
    "            pkr.inner_results.inner_results.energy,\n",
    "            pkr.inner_results.inner_results.log_accept_ratio\n",
    "                )\n",
    "#     kernel = tfp.mcmc.TransformedTransitionKernel(\n",
    "#         inner_kernel=tfp.mcmc.NoUTurnSampler(\n",
    "#             target_log_prob_fn,\n",
    "#             step_size=step_size),\n",
    "#         bijector=unconstraining_bijectors)\n",
    "\n",
    "#     hmc = tfp.mcmc.DualAveragingStepSizeAdaptation(\n",
    "#         inner_kernel=kernel,\n",
    "#         num_adaptation_steps=burnin,\n",
    "#         step_size_setter_fn=lambda pkr, new_step_size: pkr._replace(\n",
    "#               inner_results=pkr.inner_results._replace(step_size=new_step_size)),\n",
    "#         step_size_getter_fn=lambda pkr: pkr.inner_results.step_size,\n",
    "#         log_accept_prob_getter_fn=lambda pkr: pkr.inner_results.log_accept_ratio\n",
    "#       )\n",
    "    \n",
    "    \n",
    "    hmc = tfp.mcmc.TransformedTransitionKernel(\n",
    "        inner_kernel=tfp.mcmc.RandomWalkMetropolis(target_log_prob_fn),\n",
    "        bijector=unconstraining_bijectors) \n",
    "    \n",
    "    \n",
    "\n",
    "    # Sampling from the chain.\n",
    "    return tfp.mcmc.sample_chain(\n",
    "        num_results=num_steps,\n",
    "        num_burnin_steps=burnin,\n",
    "        current_state=init_state,\n",
    "        kernel=hmc)\n",
    "#         trace_fn=trace_fn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aa=np.load('../logs/GAS/LRminus3_NComps60/chkpt/iter10000.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(aa)\n",
    "aa[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=-3.0486903>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha = [0.1,0.2,0.7]\n",
    "mu = np.random.randn(3,2).astype('float32')\n",
    "sig = np.zeros((3,2,2)).astype('float32')\n",
    "sig[0] = tfb.FillScaleTriL(diag_bijector=tfb.Exp()).forward(np.random.randn(3).astype('float32'))\n",
    "sig[1] = tfb.FillScaleTriL(diag_bijector=tfb.Exp()).forward(np.random.randn(3).astype('float32'))\n",
    "sig[2] = tfb.FillScaleTriL(diag_bijector=tfb.Exp()).forward(np.random.randn(3).astype('float32'))\n",
    "dist=tfd.MixtureSameFamily(mixture_distribution=tfd.Categorical(probs=alpha),\n",
    "                          components_distribution=tfd.MultivariateNormalTriL(loc=mu,scale_tril=sig))\n",
    "ss = dist.sample(10000).numpy()\n",
    "tf.reduce_mean(dist.log_prob(ss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning Marginals\n",
      "Marginals learnt in 2.85 s.\n",
      "@ Iter:0, Training error: 0.10003776848316193, LogPriors: (2.77, 2.77), Time Elapsed: 9.6 s\n",
      "@ Iter:500, Training error: -0.3778989315032959, LogPriors: (2.77, 2.77), Time Elapsed: 16.0 s\n",
      "@ Iter:1000, Training error: -0.2882385551929474, LogPriors: (2.77, 2.77), Time Elapsed: 22.4 s\n",
      "@ Iter:1500, Training error: -0.24300140142440796, LogPriors: (2.77, 2.77), Time Elapsed: 29.0 s\n",
      "@ Iter:2000, Training error: -0.21369384229183197, LogPriors: (2.77, 2.77), Time Elapsed: 35.7 s\n",
      "@ Iter:2500, Training error: -0.297603577375412, LogPriors: (2.77, 2.77), Time Elapsed: 42.4 s\n",
      "@ Iter:3000, Training error: -0.25312918424606323, LogPriors: (2.77, 2.77), Time Elapsed: 49.2 s\n",
      "@ Iter:3500, Training error: -0.24207094311714172, LogPriors: (2.77, 2.77), Time Elapsed: 56.0 s\n",
      "@ Iter:4000, Training error: -0.23808158934116364, LogPriors: (2.77, 2.77), Time Elapsed: 62.8 s\n",
      "@ Iter:4500, Training error: -0.25017836689949036, LogPriors: (2.77, 2.77), Time Elapsed: 69.6 s\n"
     ]
    }
   ],
   "source": [
    "gmcm_obj = GMCM(2, ss)\n",
    "ll_trn=gmcm_obj.fit_GMC_dist(2,max_iters=5000,batch_size=50,initialization=['random',0], print_interval=500, regularize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=-3.195995>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(ll_trn)\n",
    "tf.reduce_mean(gmcm_obj.distribution.log_prob(ss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1,), dtype=float32, numpy=array([-2.7199116], dtype=float32)>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gmcm_obj.gmc.distribution.log_prob(np.array([0.3,0.1]).astype('float32').reshape(1,-1))\n",
    "\n",
    "def target_log_prob(u_part):\n",
    "    u = tf.concat([u_part,tf.constant(0.999999,shape=(1,))],axis=0)\n",
    "    u = tf.reshape(u,shape=(1,-1))\n",
    "    return gmcm_obj.gmc.distribution.log_prob(u)\n",
    "\n",
    "init_state = tf.constant(np.random.rand(1).astype('float32'))\n",
    "target_log_prob(init_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([-0.6234164], shape=(1,), dtype=float32)\n",
      "tf.Tensor([0. 0.], shape=(2,), dtype=float32)\n",
      "[-16.32452011 -93.01185608]\n"
     ]
    }
   ],
   "source": [
    "# init_state = tf.constant(np.random.rand(2).astype('float32'))\n",
    "u_init = tf.Variable(init_state)\n",
    "with tf.GradientTape() as tape:\n",
    "    out = target_log_prob(u_init)\n",
    "grads = tape.gradient(out, u_init)\n",
    "print(out)\n",
    "print(grads)\n",
    "\n",
    "grad_fd = gradientFiniteDifferent(target_log_prob,u_init,delta=1E-4)\n",
    "print(grad_fd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tewar\\Anaconda3\\envs\\myPythonEnv\\lib\\site-packages\\tensorflow_probability\\python\\mcmc\\sample.py:342: UserWarning: Tracing all kernel results by default is deprecated. Set the `trace_fn` argument to None (the future default value) or an explicit callback that traces the values you are interested in.\n",
      "  warnings.warn('Tracing all kernel results by default is deprecated. Set '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NUTS runtime for 5 chains: 7.9406280517578125 s.\n"
     ]
    }
   ],
   "source": [
    "# Running 5 chains in parallel\n",
    "n_chains = 5\n",
    "init_state = tf.constant(np.random.rand(2).astype('float32'))\n",
    "step_size= 0.1\n",
    "# bijector to map contrained parameters to real\n",
    "ts = time.time()\n",
    "output_NUTS = run_chain(init_state, step_size, target_log_prob,num_steps=10,burnin=50)\n",
    "print(f'NUTS runtime for {n_chains} chains: {time.time()-ts} s.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ess = tfp.mcmc.effective_sample_size(output_NUTS.all_states)\n",
    "ess = tfp.transpose(ess).numpy()\n",
    "plot(ess)\n",
    "total_samples_all_chains = np.prod(output_NUTS.all_states.shape[:2])\n",
    "total_samples = tf.reshape(output_NUTS.all_states,shape=(total_samples_all_chains,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10, 2), dtype=float32, numpy=\n",
       "array([[ 0.01819915, -0.52441907],\n",
       "       [ 0.01819915, -0.52441907],\n",
       "       [ 0.01819915, -0.52441907],\n",
       "       [ 0.01819915, -0.52441907],\n",
       "       [ 0.01819915, -0.52441907],\n",
       "       [ 0.01819915, -0.52441907],\n",
       "       [ 0.01819915, -0.52441907],\n",
       "       [ 0.01819915, -0.52441907],\n",
       "       [ 0.01819915, -0.52441907],\n",
       "       [ 0.01819915, -0.52441907]], dtype=float32)>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_NUTS.all_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n"
     ]
    }
   ],
   "source": [
    "u_vec = np.linspace(0.001,0.9999,50).astype('float32').reshape(-1,1)\n",
    "p_vec = np.zeros(50)\n",
    "for i in range(50):\n",
    "    p_vec[i] = target_log_prob(u_vec[i])\n",
    "    if i%10 ==0:\n",
    "        print(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1c3d86e6e48>]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(u_vec,tf.exp(p_vec),'k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
