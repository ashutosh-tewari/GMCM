{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install tensorflow-probability==0.15.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# magic command for automatic reload of python modules without needing to restart the notebook\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sc\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "tfd=tfp.distributions\n",
    "tfb=tfp.bijectors\n",
    "from scipy import io\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import mixture\n",
    "import joblib as jbl\n",
    "import sys\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "from mixture_models import GMCM\n",
    "\n",
    "\n",
    "# import utils as utl\n",
    "# from fitter import Fitter\n",
    "# sys.path.append('C:/Users/tewar/Documents/work/BNAF-master/data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking the device specification\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples = 150, Number of dimensions = 4\n",
      "Learning Marginals\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-15 19:12:17.315868: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2022-12-15 19:12:17.315931: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (ip-172-16-4-150.ec2.internal): /proc/driver/nvidia/version does not exist\n",
      "2022-12-15 19:12:17.316614: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Marginals learnt in 2.18 s.\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow2_p38/lib/python3.8/site-packages/tensorflow_probability/python/distributions/distribution.py:342: calling MultivariateNormalDiag.__init__ (from tensorflow_probability.python.distributions.mvn_diag) with scale_identity_multiplier is deprecated and will be removed after 2020-01-01.\n",
      "Instructions for updating:\n",
      "`scale_identity_multiplier` is deprecated; please combine it into `scale_diag` directly instead.\n",
      "@ Iter:0, Training error: 0.23811277747154236, LogPriors: (5.53, 5.53), Time Elapsed: 4.3 s\n",
      "@ Iter:100, Training error: -1.8713642358779907, LogPriors: (5.53, 5.53), Time Elapsed: 5.4 s\n",
      "@ Iter:200, Training error: -1.6491066217422485, LogPriors: (5.53, 5.53), Time Elapsed: 7.5 s\n",
      "@ Iter:300, Training error: -1.6904958486557007, LogPriors: (5.53, 5.53), Time Elapsed: 9.6 s\n",
      "@ Iter:400, Training error: -1.8560012578964233, LogPriors: (5.53, 5.53), Time Elapsed: 11.7 s\n",
      "@ Iter:500, Training error: -2.287461757659912, LogPriors: (5.52, 5.53), Time Elapsed: 13.7 s\n",
      "@ Iter:600, Training error: -2.4929795265197754, LogPriors: (5.53, 5.53), Time Elapsed: 14.9 s\n",
      "@ Iter:700, Training error: -2.3293662071228027, LogPriors: (5.53, 5.53), Time Elapsed: 16.1 s\n",
      "@ Iter:800, Training error: -2.2762603759765625, LogPriors: (5.53, 5.53), Time Elapsed: 17.3 s\n",
      "@ Iter:900, Training error: -2.5718767642974854, LogPriors: (5.53, 5.53), Time Elapsed: 18.5 s\n",
      "Learning Marginals\n",
      "Marginals learnt in 1.44 s.\n",
      "@ Iter:0, Training error: 0.1696096956729889, LogPriors: (5.53, 5.53), Time Elapsed: 3.8 s\n",
      "@ Iter:100, Training error: -1.5733598470687866, LogPriors: (5.53, 5.53), Time Elapsed: 4.9 s\n",
      "@ Iter:200, Training error: -2.8952598571777344, LogPriors: (5.52, 5.53), Time Elapsed: 6.1 s\n",
      "@ Iter:300, Training error: -2.630894184112549, LogPriors: (5.53, 5.53), Time Elapsed: 7.2 s\n",
      "@ Iter:400, Training error: -2.349698066711426, LogPriors: (5.53, 5.53), Time Elapsed: 8.4 s\n",
      "@ Iter:500, Training error: -2.2671451568603516, LogPriors: (5.53, 5.53), Time Elapsed: 9.5 s\n",
      "@ Iter:600, Training error: -2.4118497371673584, LogPriors: (5.53, 5.53), Time Elapsed: 10.8 s\n",
      "@ Iter:700, Training error: -2.279481887817383, LogPriors: (5.53, 5.53), Time Elapsed: 12.0 s\n",
      "@ Iter:800, Training error: -2.3248465061187744, LogPriors: (5.53, 5.53), Time Elapsed: 13.2 s\n",
      "@ Iter:900, Training error: -2.734541416168213, LogPriors: (5.53, 5.53), Time Elapsed: 14.3 s\n"
     ]
    }
   ],
   "source": [
    "# Example learning GMMC on Iris dataset\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "data=load_iris().data.astype('float32')\n",
    "nsamps,ndims = data.shape\n",
    "\n",
    "\n",
    "# data_in = data.astype('float32')\n",
    "nsamps,ndims = data.shape\n",
    "print(f'Number of samples = {nsamps}, Number of dimensions = {ndims}')\n",
    "\n",
    "   \n",
    "# Training GMCM without data transformation\n",
    "# Initialing GMCM object\n",
    "gmcm_obj=GMCM(ndims, data, log_transform_data=False)\n",
    "ll_no_transform=gmcm_obj.fit_dist(n_comps=2,max_iters=1000)\n",
    "\n",
    "\n",
    "# Training GMCM with data transformation\n",
    "# Initialing GMCM object\n",
    "gmcm_obj=GMCM(ndims, data, log_transform_data=True)\n",
    "ll_transform=gmcm_obj.fit_dist(n_comps=2,max_iters=1000)\n",
    "\n",
    "# plots\n",
    "plt.plot(ll_no_transform)\n",
    "plt.plot(ll_transform)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f59240219d0>]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(ll_no_transform)\n",
    "plt.plot(ll_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled=gmcm_obj.distribution.sample(150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(data[:,0],data[:,3],'ro')\n",
    "plt.plot(sampled[:,0],sampled[:,3],'ks')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gmcm_obj."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_set = ['GAS','POWER','HEPMASS']\n",
    "\n",
    "# from gas import GAS\n",
    "# from power import POWER\n",
    "# from hepmass import HEPMASS\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "\n",
    "n_reps = 1\n",
    "ll_list = []\n",
    "\n",
    "for i in range(n_reps):\n",
    "#     if data_set[i] is 'GAS':\n",
    "#         gg=GAS('C:/Users/tewar/Documents/work/GMCM/data/gas/ethylene_CO.pickle')\n",
    "#     elif data[i] is 'POWER':\n",
    "#         gg=POWER('C:/Users/tewar/Documents/work/GMCM/data/power/data.npy')\n",
    "#     elif data_set[i] is 'HEPMASS':\n",
    "#         gg=HEPMASS('C:/Users/tewar/Documents/work/GMCM/data/hepmass/')\n",
    "\n",
    "#     data = gg.trn.x\n",
    "    \n",
    "    data=load_iris().data\n",
    "    \n",
    "    nsamps,ndims = data.shape\n",
    "    np.random.seed(0)\n",
    "#     idx_selected = np.unique(np.random.randint(0,nsamps,int(nsamps/50)))\n",
    "#     data_in = data[idx_selected,:].astype('float32')\n",
    "    \n",
    "    data_in = data.astype('float32')\n",
    "\n",
    "    nsamps,ndims = data_in.shape\n",
    "    print(f'Number of samples = {nsamps}, Number of dimensions = {ndims}')\n",
    "\n",
    "    min_val = np.min(data_in).astype('float32')-1\n",
    "    shift_exp_bijec = tfb.Chain([tfb.Shift(shift=min_val.astype('float32')),tfb.Exp()])\n",
    "    np.random.shuffle(data_in)\n",
    "    data_in_trn,data_in_tst = np.split(data_in,[int(np.round(nsamps*0.75))])\n",
    "    \n",
    "    gmcm_obj = GMCM(ndims, data_in_trn, forward_transform=shift_exp_bijec)\n",
    "    ll_reg = np.zeros((500,n_reps))\n",
    "    ll_nonreg = np.zeros((500,n_reps))\n",
    "    for rep in range(n_reps):\n",
    "        print(rep)\n",
    "        ll_reg[:,rep]=gmcm_obj.fit_GMC_dist(10,max_iters=500,batch_size=5,initialization=['random',rep], print_interval=500, regularize=True)\n",
    "        print(tf.reduce_mean(gmcm_obj.distribution.log_prob(data_in_tst)))\n",
    "        \n",
    "        ll_nonreg[:,rep]=gmcm_obj.fit_GMC_dist(10,max_iters=500,batch_size=5,initialization=['random',rep], print_interval=500, regularize=False)\n",
    "        print(tf.reduce_mean(gmcm_obj.distribution.log_prob(data_in_tst)))\n",
    "    ll_list.append([ll_reg,ll_nonreg])\n",
    "\n",
    "# jbl.dump(ll_list,'regularization_impact')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ll_reg[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from power import POWER\n",
    "gg=POWER('C:/Users/tewar/Documents/work/GMCM/data/power/data.npy')\n",
    "data = gg.trn.x\n",
    "nsamps,ndims = data.shape\n",
    "idx_selected = np.unique(np.random.randint(0,nsamps,int(nsamps/50)))\n",
    "data_in = data[idx_selected,:].astype('float32')\n",
    "# data_in = np.random.randn(1000,10).astype('float32')\n",
    "min_val = np.min(data_in).astype('float32')-1\n",
    "shift_exp_bijec = tfb.Chain([tfb.Shift(shift=min_val.astype('float32')),tfb.Exp()])\n",
    "gmcm_obj = GMCM(ndims, data_in, forward_transform=shift_exp_bijec)\n",
    "ll_trn=gmcm_obj.fit_GMC_dist(5,max_iters=5,batch_size=50,initialization=['random',1], print_interval=500, regularize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl,vals = [0, 2, 3, 5], [0.1, -2, 1.2, 3.4]\n",
    "marg_gmcm = gmcm_obj.get_marginal(dl)\n",
    "cond_gmcm = gmcm_obj.get_conditional(dl,vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vv_all = np.array([0.1, 0, -2, 1.2, 0, 3.4]).astype('float32').reshape(1,-1)\n",
    "vv_obs = np.array(vals).astype('float32').reshape(1,-1)\n",
    "vv_unobs = np.array([0.,0.]).astype('float32').reshape(1,-1)\n",
    "print(gmcm_obj.distribution.log_prob(vv_all) - marg_gmcm.distribution.log_prob(vv_obs))\n",
    "print(cond_gmcm.distribution.log_prob(vv_unobs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out1 = vec2gmm_params(gmcm_obj.ndims,gmcm_obj.ncomps,gmcm_obj.gmc.params)\n",
    "out2 = vec2gmm_params(marg_gmcm.ndims, marg_gmcm.ncomps,marg_gmcm.gmc.params)\n",
    "out3 = vec2gmm_params(cond_gmcm.ndims, cond_gmcm.ncomps,cond_gmcm.gmc.params)\n",
    "\n",
    "\n",
    "print(tf.math.softmax(out1[0]))\n",
    "print(tf.math.softmax(out2[0]))\n",
    "print(tf.math.softmax(out3[0]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = gmcm_obj.distribution.sample(10000)\n",
    "data2 = marg_gmcm.distribution.sample(10000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vv =np.array([1,1.,1]).astype('float32').reshape(1,-1)\n",
    "vv1 = marg_gmcm.distribution.bijector.inverse(vv)\n",
    "print(vv1)\n",
    "vv2 = marg_gmcm.distribution.distribution.bijector.inverse(vv1)\n",
    "print(vv2)\n",
    "vv3 = marg_gmcm.distribution.distribution.distribution.bijector.inverse(vv2)\n",
    "print(vv3)\n",
    "\n",
    "obj = marg_gmcm\n",
    "while hasattr(obj.distribution,'bijector'):\n",
    "    vv = obj.distribution.bijector.inverse(vv).numpy()\n",
    "    print(vv)\n",
    "    obj = obj.distribution\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(data1[:,3],data1[:,0],'k.');\n",
    "plt.plot(data2[:,1],data2[:,0],'r.');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.semilogy(ll_trn+10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(ll_1)\n",
    "np.mean(ll_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gmcm_obj.gmc.total_trainable_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_in_tst.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = gmcm_obj.distribution.sample(2000).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id1,id2 = np.random.choice(ndims,2)\n",
    "plt.subplot(121)\n",
    "plt.plot(ss[:,id1],ss[:,id2],'k.')\n",
    "plt.subplot(122)\n",
    "plt.plot(data_in[:,id1],data_in[:,id2],'k.')\n",
    "print([id1,id2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.hist(ss[:,id2],20);\n",
    "plt.hist(data_in[:,id2],50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(np.log(data_in[:,1]+1),50);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('../logs/GAS/LRminus3_NComps60/chkpt/')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def run_chain(init_state,step_size,target_log_prob_fn, unconstraining_bijectors=tfb.Identity(),num_steps=1000,burnin=50):\n",
    "    def trace_fn(_,pkr):\n",
    "        return (\n",
    "            pkr.inner_results.inner_results.target_log_prob,\n",
    "            pkr.inner_results.inner_results.leapfrogs_taken,\n",
    "            pkr.inner_results.inner_results.has_divergence,\n",
    "            pkr.inner_results.inner_results.energy,\n",
    "            pkr.inner_results.inner_results.log_accept_ratio\n",
    "                )\n",
    "#     kernel = tfp.mcmc.TransformedTransitionKernel(\n",
    "#         inner_kernel=tfp.mcmc.NoUTurnSampler(\n",
    "#             target_log_prob_fn,\n",
    "#             step_size=step_size),\n",
    "#         bijector=unconstraining_bijectors)\n",
    "\n",
    "#     hmc = tfp.mcmc.DualAveragingStepSizeAdaptation(\n",
    "#         inner_kernel=kernel,\n",
    "#         num_adaptation_steps=burnin,\n",
    "#         step_size_setter_fn=lambda pkr, new_step_size: pkr._replace(\n",
    "#               inner_results=pkr.inner_results._replace(step_size=new_step_size)),\n",
    "#         step_size_getter_fn=lambda pkr: pkr.inner_results.step_size,\n",
    "#         log_accept_prob_getter_fn=lambda pkr: pkr.inner_results.log_accept_ratio\n",
    "#       )\n",
    "    \n",
    "    \n",
    "    hmc = tfp.mcmc.TransformedTransitionKernel(\n",
    "        inner_kernel=tfp.mcmc.RandomWalkMetropolis(target_log_prob_fn),\n",
    "        bijector=unconstraining_bijectors) \n",
    "    \n",
    "    \n",
    "\n",
    "    # Sampling from the chain.\n",
    "    return tfp.mcmc.sample_chain(\n",
    "        num_results=num_steps,\n",
    "        num_burnin_steps=burnin,\n",
    "        current_state=init_state,\n",
    "        kernel=hmc)\n",
    "#         trace_fn=trace_fn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aa=np.load('../logs/GAS/LRminus3_NComps60/chkpt/iter10000.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(aa)\n",
    "aa[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = [0.1,0.2,0.7]\n",
    "mu = np.random.randn(3,2).astype('float32')\n",
    "sig = np.zeros((3,2,2)).astype('float32')\n",
    "sig[0] = tfb.FillScaleTriL(diag_bijector=tfb.Exp()).forward(np.random.randn(3).astype('float32'))\n",
    "sig[1] = tfb.FillScaleTriL(diag_bijector=tfb.Exp()).forward(np.random.randn(3).astype('float32'))\n",
    "sig[2] = tfb.FillScaleTriL(diag_bijector=tfb.Exp()).forward(np.random.randn(3).astype('float32'))\n",
    "dist=tfd.MixtureSameFamily(mixture_distribution=tfd.Categorical(probs=alpha),\n",
    "                          components_distribution=tfd.MultivariateNormalTriL(loc=mu,scale_tril=sig))\n",
    "ss = dist.sample(10000).numpy()\n",
    "tf.reduce_mean(dist.log_prob(ss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gmcm_obj = GMCM(2, ss)\n",
    "ll_trn=gmcm_obj.fit_GMC_dist(2,max_iters=5000,batch_size=50,initialization=['random',0], print_interval=500, regularize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(ll_trn)\n",
    "tf.reduce_mean(gmcm_obj.distribution.log_prob(ss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gmcm_obj.gmc.distribution.log_prob(np.array([0.3,0.1]).astype('float32').reshape(1,-1))\n",
    "\n",
    "def target_log_prob(u_part):\n",
    "    u = tf.concat([u_part,tf.constant(0.999999,shape=(1,))],axis=0)\n",
    "    u = tf.reshape(u,shape=(1,-1))\n",
    "    return gmcm_obj.gmc.distribution.log_prob(u)\n",
    "\n",
    "init_state = tf.constant(np.random.rand(1).astype('float32'))\n",
    "target_log_prob(init_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init_state = tf.constant(np.random.rand(2).astype('float32'))\n",
    "u_init = tf.Variable(init_state)\n",
    "with tf.GradientTape() as tape:\n",
    "    out = target_log_prob(u_init)\n",
    "grads = tape.gradient(out, u_init)\n",
    "print(out)\n",
    "print(grads)\n",
    "\n",
    "grad_fd = gradientFiniteDifferent(target_log_prob,u_init,delta=1E-4)\n",
    "print(grad_fd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running 5 chains in parallel\n",
    "n_chains = 5\n",
    "init_state = tf.constant(np.random.rand(2).astype('float32'))\n",
    "step_size= 0.1\n",
    "# bijector to map contrained parameters to real\n",
    "ts = time.time()\n",
    "output_NUTS = run_chain(init_state, step_size, target_log_prob,num_steps=10,burnin=50)\n",
    "print(f'NUTS runtime for {n_chains} chains: {time.time()-ts} s.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ess = tfp.mcmc.effective_sample_size(output_NUTS.all_states)\n",
    "ess = tfp.transpose(ess).numpy()\n",
    "plot(ess)\n",
    "total_samples_all_chains = np.prod(output_NUTS.all_states.shape[:2])\n",
    "total_samples = tf.reshape(output_NUTS.all_states,shape=(total_samples_all_chains,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_NUTS.all_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u_vec = np.linspace(0.001,0.9999,50).astype('float32').reshape(-1,1)\n",
    "p_vec = np.zeros(50)\n",
    "for i in range(50):\n",
    "    p_vec[i] = target_log_prob(u_vec[i])\n",
    "    if i%10 ==0:\n",
    "        print(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(u_vec,tf.exp(p_vec),'k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Numerically finding the icdf values for a distribution whos analytical CDF is specified\n",
    "# def icdf_numerical(u,cdf_funct,lb,ub):\n",
    "#     # setting up the numerical method (Chandrupatla root finding algorithm) to find icdf\n",
    "#     obj_func = lambda x: cdf_funct(x) - u\n",
    "#     # finding the roots\n",
    "#     x = tfp.math.find_root_chandrupatla(obj_func,low=lb,high=ub)[0]\n",
    "#     return x\n",
    "\n",
    "# # Standardize GMM parameters\n",
    "# def standardize_gmm_params(alphas,mus,covs):\n",
    "#     weighted_mus = tf.linalg.matvec(tf.transpose(mus),alphas)\n",
    "#     new_mus = mus - weighted_mus\n",
    "#     variances = tf.linalg.diag_part(covs)\n",
    "#     scaling_vec = tf.linalg.matvec(tf.transpose(new_mus**2+variances),alphas)\n",
    "#     scaling_matrix = tf.linalg.diag(1/(scaling_vec**0.5))\n",
    "#     new_mus = tf.linalg.matmul(new_mus,scaling_matrix)\n",
    "#     new_covs = tf.linalg.matmul(covs,scaling_matrix**2)\n",
    "#     return alphas,new_mus,new_covs\n",
    "\n",
    "# def vec2gmm_params(n_dims,n_comps,param_vec):\n",
    "#     num_alpha_params = n_comps\n",
    "#     num_mu_params = n_comps*n_dims\n",
    "#     num_sig_params = int(n_comps*n_dims*(n_dims+1)*0.5)\n",
    "#     logit_param, mu_param, chol_param = tf.split(param_vec,[num_alpha_params,num_mu_params,num_sig_params])\n",
    "#     mu_vectors = tf.reshape(mu_param, shape=(n_comps,n_dims))\n",
    "#     chol_mat_array=tf.TensorArray(tf.float32,size=n_comps)\n",
    "#     cov_mat_array=tf.TensorArray(tf.float32,size=n_comps)\n",
    "#     for k in range(n_comps):\n",
    "#         start_idx = tf.cast(k*(num_sig_params/n_comps),tf.int32)\n",
    "#         end_idx = tf.cast((k+1)*(num_sig_params/n_comps),tf.int32)\n",
    "#         chol_mat = tfb.FillScaleTriL(diag_bijector=tfb.Exp()).forward(chol_param[start_idx:end_idx])\n",
    "#         cov_mat = tf.matmul(chol_mat,tf.transpose(chol_mat))\n",
    "#         chol_mat_array = chol_mat_array.write(k,chol_mat) \n",
    "#         cov_mat_array =  cov_mat_array.write(k,cov_mat) \n",
    "        \n",
    "#     chol_matrices = chol_mat_array.stack()\n",
    "#     cov_matrices = cov_mat_array.stack()     \n",
    "#     return [logit_param,mu_vectors,cov_matrices,chol_matrices]\n",
    "\n",
    "# def gmm_params2vec(n_dims,n_comps,alphas,mu_vectors,cov_matrices):\n",
    "#     # now gathering all the parameters into a single vector\n",
    "#     param_list = []\n",
    "#     param_list.append(np.log(alphas))\n",
    "#     param_list.append(tf.reshape(mu_vectors,-1))\n",
    "#     for k in range(n_comps):\n",
    "#         chol_mat = tf.linalg.cholesky(cov_matrices[k])\n",
    "#         param_list.append(tfb.FillScaleTriL(diag_bijector=tfb.Exp()).inverse(chol_mat))\n",
    "#     param_vec = tf.concat(param_list,axis=0)\n",
    "#     return param_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # GMC bijector\n",
    "# class GMC_bijector(tfb.Bijector):\n",
    "#     def __init__(self,n_dims,n_comps,param_list,forward_min_event_ndims=1, validate_args: bool = False,name=\"gmc\"):\n",
    "#         super(GMC_bijector, self).__init__(\n",
    "#             validate_args=validate_args, forward_min_event_ndims=forward_min_event_ndims, name=name\n",
    "#         )\n",
    "        \n",
    "#         assert (len(param_list)==3), 'incorrect number of inputs'\n",
    "#         assert param_list[1].shape == [n_comps,n_dims], 'the dimension of mean vectors should be ncomps x ndims'\n",
    "#         assert param_list[2].shape == [n_comps,n_dims], 'the dimension of variance vectors should be ncomps x ndims'\n",
    "        \n",
    "#         self.ndims = n_dims\n",
    "#         self.ncomps = n_comps\n",
    "#         self.logits = param_list[0]\n",
    "#         self.mu_vectors = param_list[1]\n",
    "#         self.var_vectors = param_list[2]\n",
    "#         self.std_vectors = self.var_vectors**0.5\n",
    "    \n",
    "#     def _forward(self, x_mat):\n",
    "#         assert x_mat.shape[1] == self.ndims, 'expected data dimensions n_samps x n_dims'\n",
    "#         dist = tfd.MixtureSameFamily(mixture_distribution=tfd.Categorical(logits=self.logits),\n",
    "#                                components_distribution=tfd.Normal(loc=tf.transpose(self.mu_vectors),\n",
    "#                                                                   scale=tf.transpose(self.std_vectors)))\n",
    "#         u_mat = dist.cdf(x_mat)\n",
    "#         return u_mat\n",
    "    \n",
    "#     def _inverse(self, u_mat):\n",
    "#         assert u_mat.shape[1] == self.ndims, 'expected data dimensions n_samps x n_dims'\n",
    "#         x_mat = self.gmm_icdf_parallel(u_mat,self.logits,tf.transpose(self.mu_vectors),tf.transpose(self.std_vectors))\n",
    "#         return x_mat\n",
    "    \n",
    "#     def _inverse_log_det_jacobian(self, u_mat):\n",
    "#         x_mat = self._inverse(u_mat)\n",
    "#         dist = tfd.MixtureSameFamily(mixture_distribution=tfd.Categorical(logits=self.logits),\n",
    "#                                components_distribution=tfd.Normal(loc=tf.transpose(self.mu_vectors),\n",
    "#                                                                   scale=tf.transpose(self.std_vectors)))\n",
    "#         log_det_J_mat = dist.log_prob(x_mat)\n",
    "#         return -tf.reduce_sum(log_det_J_mat,axis=1)    \n",
    "    \n",
    "#     # Numerically finding the icdf values of univariate gmm distributions (one along each dimension)\n",
    "#     @tf.custom_gradient\n",
    "#     def gmm_icdf_parallel(self,u_mat,logit,mu_T,std_T):\n",
    "#         # Setting up the numerical method to find icdf\n",
    "#         # first define a function that computes the residual between the actual true CDF values and the CDF value as specified matrix\n",
    "#         obj_func = lambda x: tfd.MixtureSameFamily(mixture_distribution=tfd.Categorical(logits=logit),\n",
    "#                                                    components_distribution=tfd.Normal(loc=mu_T,scale=std_T)).cdf(x)-u_mat\n",
    "#         # specifying the lower and upper bounds of the root based on current parameters\n",
    "#         lb = tf.reduce_min(mu_T,axis=1) - 5*tf.reduce_max(std_T,axis=1)\n",
    "#         ub = tf.reduce_max(mu_T,axis=1) + 5*tf.reduce_max(std_T,axis=1)\n",
    "#         # replicating the lower and upper bounds\n",
    "#         lb = tf.repeat(tf.reshape(lb,[1,-1]),u_mat.shape[0],axis=0)\n",
    "#         ub = tf.repeat(tf.reshape(ub,[1,-1]),u_mat.shape[0],axis=0)\n",
    "#         # finding the roots (Chandrupatla root finding algorithm)\n",
    "#         x_mat = tfp.math.find_root_chandrupatla(obj_func,low=lb,high=ub)[0]\n",
    "#         # following code implements custom gradient\n",
    "#         def grad(dy):\n",
    "#             # Calling  another python function to get the partial derivatives\n",
    "#             grad_logit, grad_mu, grad_std = self.partial_deriv_z(x_mat,logit,mu_T,std_T)\n",
    "\n",
    "#             temp_mat = tf.linalg.matmul(grad_logit,dy)\n",
    "\n",
    "#             logit_grad = tf.linalg.diag_part(temp_mat)\n",
    "#             logit_grad = tf.reduce_sum(logit_grad,axis=1)\n",
    "\n",
    "#             temp_mat = tf.linalg.matmul(grad_mu,dy)\n",
    "#             mu_grad = tf.linalg.diag_part(temp_mat)\n",
    "\n",
    "#             temp_mat = tf.linalg.matmul(grad_std,dy)\n",
    "#             std_grad = tf.linalg.diag_part(temp_mat)\n",
    "            \n",
    "#             return tf.constant(0.,shape=(u_mat.shape)), logit_grad, tf.transpose(mu_grad), tf.transpose(std_grad)    \n",
    "#         return x_mat, grad\n",
    "    \n",
    "#     # Analytical partial derivative of icdf of Gaussian Mixture marginals\n",
    "#     def partial_deriv_z(self,z,logit,mu_T,std_T):\n",
    "#         alpha = tf.math.softmax(logit)\n",
    "#         grad_logit_array = tf.TensorArray(tf.float32, size=self.ncomps)\n",
    "#         grad_mu_array = tf.TensorArray(tf.float32, size=self.ncomps)\n",
    "#         grad_var_array = tf.TensorArray(tf.float32, size=self.ncomps)        \n",
    "#         dist = tfd.MixtureSameFamily(mixture_distribution=tfd.Categorical(logits=logit),\n",
    "#                                 components_distribution=tfd.Normal(loc=mu_T,\n",
    "#                                                                    scale=std_T))\n",
    "#         common_factor1 = dist.prob(z)\n",
    "#         for k in range(self.ncomps):        \n",
    "#             common_factor2 = tfd.Normal(loc=mu_T[:,k],scale=std_T[:,k]).prob(z)\n",
    "#             term = 0.5*(1+tf.math.erf((z-mu_T[:,k])/(tf.math.sqrt(2.)*std_T[:,k])))\n",
    "#             v1 = -alpha[k]*(term - dist.cdf(z))/common_factor1\n",
    "#             v2 = alpha[k]*common_factor2/common_factor1\n",
    "#             v3 = v2 * ((z-mu_T[:,k])/(std_T[:,k])) \n",
    "\n",
    "#             grad_logit_array = grad_logit_array.write(k, tf.transpose(v1) )\n",
    "#             grad_mu_array = grad_mu_array.write(k, tf.transpose(v2) )\n",
    "#             grad_var_array = grad_var_array.write(k, tf.transpose(v3) )\n",
    "#         return grad_logit_array.stack(), grad_mu_array.stack(), grad_var_array.stack()\n",
    "    \n",
    "#  # Marignal transform bijector\n",
    "# class Marginal_transform(tfb.Bijector):\n",
    "#     def __init__(self,ndims,marg_dist_list,forward_min_event_ndims=1, validate_args: bool = False,name=\"marginals\"):\n",
    "#         super(Marginal_transform, self).__init__(\n",
    "#             validate_args=validate_args, forward_min_event_ndims=forward_min_event_ndims, name=name\n",
    "#         )\n",
    "#         self.ndims = ndims\n",
    "#         self.marg_dists = marg_dist_list\n",
    "    \n",
    "#     def _inverse(self, x_mat):\n",
    "#         nobs = x_mat.get_shape().as_list()[0]\n",
    "#         temp_array = tf.TensorArray(tf.float32,size=self.ndims)\n",
    "#         for j in range(self.ndims):\n",
    "#             u_cur = self.marg_dists[j]['cdf'](x_mat[:,j])\n",
    "#             temp_array = temp_array.write(j,u_cur)\n",
    "#         u_mat = tf.transpose(temp_array.stack())            \n",
    "#         return u_mat\n",
    "    \n",
    "#     def _forward(self, u_mat):\n",
    "#         temp_array = tf.TensorArray(tf.float32,size=self.ndims)\n",
    "#         for j in range(self.ndims):\n",
    "#             x_cur = icdf_numerical(u_mat[:,j], self.marg_dists[j]['cdf'],self.marg_dists[j]['lb'],self.marg_dists[j]['ub'])\n",
    "#             temp_array = temp_array.write(j,x_cur)\n",
    "#         x_mat = tf.transpose(temp_array.stack())              \n",
    "#         return x_mat\n",
    "    \n",
    "#     def _forward_log_det_jacobian(self, u_mat):\n",
    "#         x_mat = self._forward(u_mat)\n",
    "#         temp_array = tf.TensorArray(tf.float32,size=self.ndims)\n",
    "#         for j in range(self.ndims):\n",
    "#             temp_array = temp_array.write(j,self.marg_dists[j]['log_pdf'](x_mat[:,j]))\n",
    "#         log_det_J_mat = tf.transpose(temp_array.stack())\n",
    "#         return -tf.reduce_sum(log_det_J_mat,axis=1) \n",
    "    \n",
    "#     def _inverse_log_det_jacobian(self, x_mat):\n",
    "#         u_mat = self._inverse(x_mat)\n",
    "#         return -self._forward_log_det_jacobian(u_mat)   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Defining GMC class\n",
    "# class GMC:\n",
    "#     def __init__(self, n_dims, n_comps, param_vec):        \n",
    "#         self.ndims = n_dims\n",
    "#         self.ncomps = n_comps   \n",
    "#         self.total_trainable_params = int(n_comps*(1+n_dims+0.5*n_dims*(n_dims+1)))\n",
    "#         self.params = param_vec\n",
    "#         assert tf.size(param_vec) == self.total_trainable_params, 'the supplied parameter vector is not commensurate with the n_dims, and n_comps'\n",
    "        \n",
    "#     @property\n",
    "#     def distribution(self):\n",
    "#         # transforming vector in to parameters\n",
    "#         logits,mus,covs,chols = vec2gmm_params(self.ndims,self.ncomps,self.params)\n",
    "#         # Instantiating the bijector\n",
    "#         gmc_bijector = GMC_bijector(self.ndims, self.ncomps, [logits, mus, tf.linalg.diag_part(covs)])\n",
    "#         # Specifying the base distribution\n",
    "#         base_dist = tfd.MixtureSameFamily(tfd.Categorical(logits=logits),\n",
    "#                                           tfd.MultivariateNormalTriL(loc=mus,scale_tril=chols))\n",
    "#         # Instnatiating the gmc distribution as a transformed distribtution\n",
    "#         gmc_dist = tfd.TransformedDistribution(distribution=base_dist,bijector=gmc_bijector)    \n",
    "#         return gmc_dist   \n",
    "    \n",
    "#     @property\n",
    "#     def identifiability_prior(self):\n",
    "#         # transforming vector in to parameters\n",
    "#         logits,mus,covs,_ = vec2gmm_params(self.ndims,self.ncomps,self.params)        \n",
    "#         alphas = tf.math.softmax(logits)\n",
    "#         variances = tf.linalg.diag_part(covs)        \n",
    "#         vec1 = tf.linalg.matvec(tf.transpose(mus),alphas)\n",
    "#         vec2 = tf.linalg.matvec(tf.transpose(variances + mus**2),alphas)\n",
    "#         log_prior_1 = tfd.MultivariateNormalDiag(loc=tf.zeros(self.ndims),scale_diag=1E-1*tf.ones(self.ndims)).log_prob(vec1)\n",
    "#         log_prior_2 = tfd.MultivariateNormalDiag(loc=tf.ones(self.ndims) ,scale_diag=1E-1*tf.ones(self.ndims)).log_prob(vec2)\n",
    "#         return log_prior_1,log_prior_2\n",
    "    \n",
    "\n",
    "    \n",
    "# class GMCM:\n",
    "#     def __init__(self, n_dims, data_in, forward_transform=None, marginals_list=None, gmc=None):\n",
    "        \n",
    "#         self.ndims = n_dims\n",
    "#         self.data_transform = forward_transform\n",
    "#         self.gmc = gmc\n",
    "#         if gmc is not None:\n",
    "#             self.ncomps = gmc.ncomps\n",
    "        \n",
    "#         if forward_transform is not None:\n",
    "#             data_in = forward_transform.inverse(data_in).numpy()\n",
    "#         self.data_in = data_in\n",
    "        \n",
    "#         if marginals_list is None:\n",
    "#             print('Learning Marginals')\n",
    "#             ts = time.time()\n",
    "#             marginals_list = self.learn_marginals()\n",
    "#             print(f'Marginals learnt in {np.round(time.time()-ts,2)} s.') \n",
    "        \n",
    "#         self.marg_dists = marginals_list\n",
    "#         self.marg_bijector = Marginal_transform(self.ndims,self.marg_dists)       \n",
    "        \n",
    "#     @property\n",
    "#     def distribution(self):\n",
    "#         # setting the gmcm distribution as a transformed distribution of gmc_distribution\n",
    "#         gmcm_dist = tfd.TransformedDistribution(distribution=self.gmc.distribution,bijector=self.marg_bijector)\n",
    "#         if self.data_transform is not None:\n",
    "#             gmcm_dist = tfd.TransformedDistribution(distribution=gmcm_dist,bijector=self.data_transform)\n",
    "#         return gmcm_dist\n",
    "    \n",
    "    \n",
    "#     def learn_marginals(self):\n",
    "#         # fitting marginal distributions first\n",
    "#         marg_dist_list=[]\n",
    "#         for j in range(self.ndims):\n",
    "#             input_vector = self.data_in[:,j].reshape(-1,1)\n",
    "#             marg_gmm_obj = GMM_best_fit(input_vector,max_ncomp=10)\n",
    "#             marg_gmm_tfp = tfd.MixtureSameFamily(mixture_distribution=tfd.Categorical(probs=marg_gmm_obj.weights_.flatten().astype('float32')),\n",
    "#                                                 components_distribution=tfd.Normal(loc=marg_gmm_obj.means_.flatten().astype('float32'),\n",
    "#                                                                                    scale = marg_gmm_obj.covariances_.flatten().astype('float32')**0.5),)\n",
    "            \n",
    "#             # creating a dictionary containing necessary information about each marginal distribution\n",
    "#             info_dict={'cdf':marg_gmm_tfp.cdf,\n",
    "#                        'log_pdf':marg_gmm_tfp.log_prob,\n",
    "#                        'lb':tf.reduce_min(input_vector)-3*tfp.stats.stddev(input_vector),\n",
    "#                        'ub':tf.reduce_max(input_vector)+3*tfp.stats.stddev(input_vector)                         \n",
    "#                       }\n",
    "            \n",
    "#             marg_dist_list.append(info_dict)\n",
    "        \n",
    "#         return marg_dist_list\n",
    "        \n",
    "#     def init_GMC_params(self,initialization=['random',None]):\n",
    "#         # Initializing the GMC params \n",
    "#         init_method, seed_val = initialization\n",
    "#         if init_method == 'random':\n",
    "#             if seed_val is not None:\n",
    "#                 np.random.seed(seed_val)\n",
    "#             alphas = tf.ones(self.ncomps)/self.ncomps\n",
    "#             mus = tf.constant(np.random.randn(self.ncomps,self.ndims).astype('float32'))\n",
    "#             covs = tf.repeat(tf.expand_dims(tf.eye(self.ndims),0),self.ncomps,axis=0)\n",
    "#         elif init_method == 'gmm':            \n",
    "#             gmm = mixture.GaussianMixture(n_components=self.ncomps,covariance_type='full',max_iter=1000,n_init=5)\n",
    "#             gmm.fit(self.data_in)\n",
    "#             alphas = gmm.weights_.astype('float32')\n",
    "#             mus = gmm.means_.astype('float32')\n",
    "#             covs = gmm.covariances_.astype('float32')                                                            \n",
    "        \n",
    "#         # changing the parameters to standardize the resulting gmm\n",
    "#         alphas,mus,covs = standardize_gmm_params(alphas,mus,covs)\n",
    "#         # now initializing trainable parameters\n",
    "#         init_params = tf.Variable(gmm_params2vec(self.ndims,self.ncomps,alphas,mus,covs))\n",
    "        \n",
    "#         return init_params\n",
    "    \n",
    "    \n",
    "#     def fit_GMC_dist(self, n_comps, optimizer = tf.optimizers.Adam(learning_rate=1E-2), initialization = ['random',None], max_iters = 1000, batch_size = 10, print_interval=100, regularize=True, plot_results = False):\n",
    "#         self.ncomps = n_comps\n",
    "#         # getting the marginal CDF values\n",
    "#         u_mat = self.marg_bijector.inverse(self.data_in)\n",
    "#         # initializing the parameters\n",
    "#         gmc_params = self.init_GMC_params(initialization=initialization)\n",
    "#         # instantiation GMC object\n",
    "#         gmc_obj = GMC(self.ndims,self.ncomps,gmc_params)\n",
    "        \n",
    "#         # Defining the training step\n",
    "#         @tf.function\n",
    "#         def train_step(u_selected):\n",
    "#             with tf.GradientTape() as tape:\n",
    "#                 neg_gmc_ll = -tf.reduce_mean(gmc_obj.distribution.log_prob(u_selected))\n",
    "#                 ident_prior = gmc_obj.identifiability_prior\n",
    "#                 if regularize:\n",
    "#                     total_cost = neg_gmc_ll - tf.reduce_sum(ident_prior)\n",
    "#                 else:\n",
    "#                     total_cost = neg_gmc_ll\n",
    "                    \n",
    "#             grads = tape.gradient(total_cost, gmc_obj.params)\n",
    "#             if not (tf.reduce_any(tf.math.is_nan(grads)) or tf.reduce_any(tf.math.is_inf(grads))):\n",
    "#                 optimizer.apply_gradients(zip([grads], [gmc_obj.params])) #updating the gmc parameters\n",
    "#             return neg_gmc_ll,ident_prior[0],ident_prior[1]\n",
    "\n",
    "#         neg_ll_trn = np.empty(max_iters)  \n",
    "#         neg_ll_trn[:] = np.NaN\n",
    "#         neg_prior_1 = np.empty(max_iters)  \n",
    "#         neg_prior_1[:] = np.NaN\n",
    "#         neg_prior_2 = np.empty(max_iters)  \n",
    "#         neg_prior_2[:] = np.NaN\n",
    "#         np.random.seed(10)\n",
    "#         ts = time.time() # start time\n",
    "#         # Optimization iterations\n",
    "#         for itr in np.arange(max_iters):\n",
    "#             np.random.seed(itr)\n",
    "#             # Executing a training step\n",
    "#             samps_idx = np.random.choice(u_mat.shape[0],batch_size)\n",
    "#             u_selected_trn = tf.gather(u_mat,samps_idx)\n",
    "#             out = train_step(u_selected_trn)\n",
    "#             neg_ll_trn[itr] = out[0].numpy()\n",
    "#             neg_prior_1[itr] = out[1].numpy()\n",
    "#             neg_prior_2[itr] = out[2].numpy()    \n",
    "#             # Printing results every 100 iteration    \n",
    "#             if tf.equal(itr%print_interval,0) or tf.equal(itr,0):\n",
    "#                 time_elapsed = np.round(time.time()-ts,1)\n",
    "#                 print(f'@ Iter:{itr}, Training error: {neg_ll_trn[itr]}, LogPriors: {np.round(neg_prior_1[itr],2), np.round(neg_prior_2[itr],2)}, Time Elapsed: {time_elapsed} s')    \n",
    "        \n",
    "#         if plot_results:\n",
    "#             # Plotting results\n",
    "#             plt.plot(neg_ll_trn)\n",
    "#             plt.xlabel('Iteration',fontsize=12)\n",
    "#             plt.ylabel('Neg_logLike',fontsize=12)\n",
    "#             plt.legend(['train'],fontsize=12)\n",
    "        \n",
    "#         # setting gmc distritbution embedded inside GMCM\n",
    "#         self.gmc = gmc_obj\n",
    "         \n",
    "#         return neg_ll_trn\n",
    "    \n",
    "#     def get_marginal(self,dim_list):        \n",
    "#         data_in_new = tf.gather(self.data_in,dim_list,axis=1).numpy()\n",
    "#         logits,mus,covs,_ = vec2gmm_params(self.ndims,self.ncomps,self.gmc.params)\n",
    "#         alphas = tf.math.softmax(logits)\n",
    "#         dim_remove = list(set(list(range(self.ndims)))-set(dim_list))\n",
    "#         mus_new = tf.gather(mus, dim_list, axis=1)\n",
    "#         covs_new = tf.TensorArray(tf.float32,self.ncomps)\n",
    "#         for k in range(self.ncomps):\n",
    "#             temp_mat = covs[k].numpy()\n",
    "#             covs_new = covs_new.write(k,temp_mat[np.ix_(dim_list,dim_list)])\n",
    "#         covs_new = covs_new.stack()\n",
    "#         # getting the gmc object first for the marginal gmcm\n",
    "#         marginal_gmc_params = gmm_params2vec(len(dim_list),self.ncomps,alphas,mus_new,covs_new)\n",
    "#         marg_gmc = GMC(len(dim_list),self.ncomps,marginal_gmc_params)\n",
    "#         # then getting the marginals along the specified dimensions\n",
    "#         marg_list_new = []\n",
    "#         for j in range(self.ndims):\n",
    "#             if j in dim_list:\n",
    "#                 marg_list_new.append(self.marg_dists[j])\n",
    "#         # creating the marginal gmcm object\n",
    "#         marg_gmcm_dist = GMCM(len(dim_list), data_in_new, forward_transform=self.data_transform, marginals_list=marg_list_new, gmc=marg_gmc)\n",
    "#         return marg_gmcm_dist   \n",
    "    \n",
    "#     def get_conditional(self,obs_dim_list, value_list):\n",
    "        \n",
    "#         x_obs = np.array(value_list).reshape(1,-1).astype('float32')\n",
    "#         unobs_dim_list = list(set(range(self.ndims)) - set(obs_dim_list))\n",
    "        \n",
    "#         #Obtaining the marginal distribution for the observed and missing part\n",
    "#         gmcm_observed = self.get_marginal(obs_dim_list)\n",
    "#         gmcm_unobserved = self.get_marginal(unobs_dim_list)\n",
    "        \n",
    "#         temp_obj = gmcm_observed\n",
    "#         z_obs = np.copy(x_obs)\n",
    "#         while hasattr(temp_obj.distribution,'bijector'):\n",
    "#             z_obs = temp_obj.distribution.bijector.inverse(z_obs).numpy()\n",
    "#             temp_obj = temp_obj.distribution\n",
    "\n",
    "#         #Obtaining the conditional mu and Sigma of individual compoents of the missing part given the data of observed part\n",
    "#         mus_cond = np.zeros((self.ncomps,len(unobs_dim_list))).astype('float32')\n",
    "#         covs_cond = np.zeros((self.ncomps,len(unobs_dim_list), len(unobs_dim_list))).astype('float32')\n",
    "#         logits_cond = np.zeros(self.ncomps).astype('float32')\n",
    "        \n",
    "#         logits,mus,covs,_ = vec2gmm_params(self.ndims,self.ncomps,self.gmc.params)\n",
    "#         logits_unobs,mus_unobs,covs_unobs,_ = vec2gmm_params(gmcm_unobserved.ndims,gmcm_unobserved.ncomps,gmcm_unobserved.gmc.params)\n",
    "#         logits_obs,mus_obs,covs_obs,_ = vec2gmm_params(gmcm_observed.ndims,gmcm_observed.ncomps,gmcm_observed.gmc.params)\n",
    "        \n",
    "#         for k in range(self.ncomps):\n",
    "#             sig_11 = covs_unobs.numpy()[k]\n",
    "#             sig_22 = covs_obs.numpy()[k]\n",
    "#             sig_12 = covs.numpy()[k][np.ix_(unobs_dim_list,obs_dim_list)]\n",
    "#             sig_21 = sig_12.T\n",
    "#             mu_11 = mus_unobs[k,:]\n",
    "#             mu_22 = mus_obs[k,:]\n",
    "            \n",
    "# #             temp_mat1 = np.concatenate([np.concatenate([sig_11,sig_12],axis=1),np.concatenate([sig_21,sig_22],axis=1)],axis=0)\n",
    "# #             temp_mat2=covs.numpy()[k]\n",
    "# #             lll = unobs_dim_list+obs_dim_list\n",
    "# #             temp_mat2 = temp_mat2[:,lll]\n",
    "# #             temp_mat2 = temp_mat2[lll,:]\n",
    "# #             print(temp_mat1-temp_mat2)\n",
    "            \n",
    "\n",
    "#             # Getting the conditional mu and Sigma\n",
    "#             mu_bar = mu_11 + np.matmul(sig_12,  np.linalg.solve(sig_22,z_obs.T)).flatten()\n",
    "#             sig_bar = sig_11 - np.matmul(sig_12,  np.linalg.solve(sig_22,sig_21))\n",
    "#             mus_cond[k] = mu_bar\n",
    "#             covs_cond[k] = (sig_bar+sig_bar.T)/2\n",
    "\n",
    "#             # Getting the log proability of the components conditioned on the observed data\n",
    "#             logits_cond[k] = logits_obs[k] + tfd.MultivariateNormalFullCovariance(loc=mus_obs[k],\n",
    "#                                                                                          covariance_matrix=covs_obs[k]).log_prob(z_obs)\n",
    "#         #logits to probabilities\n",
    "#         alphas_cond = tf.math.softmax(logits_cond)\n",
    "#         # parameter vector of the conditional gmc distribution\n",
    "#         conditional_gmc_params = gmm_params2vec(len(unobs_dim_list),self.ncomps,alphas_cond,mus_cond,covs_cond)\n",
    "#         cond_gmc = GMC(len(unobs_dim_list),self.ncomps,conditional_gmc_params)\n",
    "#         # then getting the marginals along the specified dimensions\n",
    "#         marg_list_new = []\n",
    "#         for j in range(self.ndims):\n",
    "#             if j in unobs_dim_list:\n",
    "#                 marg_list_new.append(self.marg_dists[j])\n",
    "#         # creating the conditional gmcm object\n",
    "#         data_in_new = tf.gather(self.data_in,unobs_dim_list,axis=1).numpy()\n",
    "#         cond_gmcm_dist = GMCM(len(unobs_dim_list), data_in_new, forward_transform=self.data_transform, marginals_list=marg_list_new, gmc=cond_gmc)\n",
    "#         return cond_gmcm_dist  \n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow2_p38",
   "language": "python",
   "name": "conda_tensorflow2_p38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
